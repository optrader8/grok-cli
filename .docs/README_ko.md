# Grok CLI - ì»¤ìŠ¤í„°ë§ˆì´ì§• ê°€ì´ë“œ

ì´ ë¬¸ì„œëŠ” Grok CLIë¥¼ ë¡œì»¬ ëª¨ë¸(gpt-oss-20b, qwen3-coder ë“±)ë¡œ ì»¤ìŠ¤í„°ë§ˆì´ì§•í•˜ê¸° ìœ„í•œ ê¸°ìˆ  ë¬¸ì„œì…ë‹ˆë‹¤.

## ëª©ì°¨

1. [í”„ë¡œì íŠ¸ êµ¬ì¡° ë¶„ì„](#í”„ë¡œì íŠ¸-êµ¬ì¡°-ë¶„ì„)
2. [API í˜¸ì¶œ ë©”ì»¤ë‹ˆì¦˜](#api-í˜¸ì¶œ-ë©”ì»¤ë‹ˆì¦˜)
3. [ë¡œì»¬ ëª¨ë¸ í†µí•© ë°©ë²•](#ë¡œì»¬-ëª¨ë¸-í†µí•©-ë°©ë²•)
4. [ì„¤ì • ê´€ë¦¬ ì‹œìŠ¤í…œ](#ì„¤ì •-ê´€ë¦¬-ì‹œìŠ¤í…œ)
5. [ì»¤ìŠ¤í„°ë§ˆì´ì§• ë¡œë“œë§µ](#ì»¤ìŠ¤í„°ë§ˆì´ì§•-ë¡œë“œë§µ)

## í”„ë¡œì íŠ¸ êµ¬ì¡° ë¶„ì„

### í•µì‹¬ ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
grok-cli/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agent/              # AI ì—ì´ì „íŠ¸ ë¡œì§
â”‚   â”‚   â”œâ”€â”€ grok-agent.ts   # ë©”ì¸ ì—ì´ì „íŠ¸ (ëŒ€í™” ì²˜ë¦¬, ë„êµ¬ ì‹¤í–‰)
â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”œâ”€â”€ grok/               # Grok API í´ë¼ì´ì–¸íŠ¸
â”‚   â”‚   â”œâ”€â”€ client.ts       # OpenAI SDK ê¸°ë°˜ API í´ë¼ì´ì–¸íŠ¸
â”‚   â”‚   â””â”€â”€ tools.ts        # ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ì •ì˜
â”‚   â”œâ”€â”€ tools/              # ê°œë³„ ë„êµ¬ êµ¬í˜„
â”‚   â”‚   â”œâ”€â”€ text-editor.ts  # íŒŒì¼ í¸ì§‘ ë„êµ¬
â”‚   â”‚   â”œâ”€â”€ bash.ts         # Bash ëª…ë ¹ ì‹¤í–‰
â”‚   â”‚   â”œâ”€â”€ morph-editor.ts # Morph ë¹ ë¥¸ í¸ì§‘
â”‚   â”‚   â”œâ”€â”€ search.ts       # íŒŒì¼ ê²€ìƒ‰
â”‚   â”‚   â””â”€â”€ todo-tool.ts    # TODO ê´€ë¦¬
â”‚   â”œâ”€â”€ ui/                 # í„°ë¯¸ë„ UI (Ink ê¸°ë°˜)
â”‚   â”œâ”€â”€ utils/              # ìœ í‹¸ë¦¬í‹°
â”‚   â”‚   â”œâ”€â”€ settings-manager.ts  # ì„¤ì • ê´€ë¦¬ì
â”‚   â”‚   â”œâ”€â”€ model-config.ts      # ëª¨ë¸ ì„¤ì •
â”‚   â”‚   â””â”€â”€ token-counter.ts     # í† í° ì¹´ìš´íŒ…
â”‚   â”œâ”€â”€ mcp/                # Model Context Protocol ì„œë²„
â”‚   â””â”€â”€ index.ts            # CLI ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸
â”œâ”€â”€ .grok/                  # í”„ë¡œì íŠ¸ë³„ ì„¤ì •
â”‚   â””â”€â”€ settings.json
â””â”€â”€ ~/.grok/                # ì‚¬ìš©ì ì „ì—­ ì„¤ì •
    â””â”€â”€ user-settings.json
```

### ì£¼ìš” ì»´í¬ë„ŒíŠ¸

#### 1. `src/grok/client.ts` - API í´ë¼ì´ì–¸íŠ¸
**ì—­í• **: Grok APIì™€ì˜ í†µì‹ ì„ ë‹´ë‹¹

**í•µì‹¬ ì½”ë“œ**:
```typescript
export class GrokClient {
  private client: OpenAI;
  private currentModel: string = "grok-code-fast-1";

  constructor(apiKey: string, model?: string, baseURL?: string) {
    this.client = new OpenAI({
      apiKey,
      baseURL: baseURL || process.env.GROK_BASE_URL || "https://api.x.ai/v1",
      timeout: 360000,
    });
  }

  async chat(
    messages: GrokMessage[],
    tools?: GrokTool[],
    model?: string
  ): Promise<GrokResponse> {
    const response = await this.client.chat.completions.create({
      model: model || this.currentModel,
      messages,
      tools: tools || [],
      temperature: 0.7,
      max_tokens: this.defaultMaxTokens,
    });
    return response as GrokResponse;
  }
}
```

**ì¤‘ìš” í¬ì¸íŠ¸**:
- OpenAI SDKë¥¼ ì‚¬ìš© (OpenAI í˜¸í™˜ API)
- `baseURL`ì„ í†µí•´ API ì—”ë“œí¬ì¸íŠ¸ ë³€ê²½ ê°€ëŠ¥
- ìŠ¤íŠ¸ë¦¬ë°ê³¼ ì¼ë°˜ ì±„íŒ… ëª¨ë‘ ì§€ì›

#### 2. `src/agent/grok-agent.ts` - ì—ì´ì „íŠ¸
**ì—­í• **: ì‚¬ìš©ì ë©”ì‹œì§€ ì²˜ë¦¬ ë° ë„êµ¬ ì‹¤í–‰ ê´€ë¦¬

**í•µì‹¬ ê¸°ëŠ¥**:
- ë©”ì‹œì§€ ì²˜ë¦¬ ë£¨í”„ (ìµœëŒ€ 400ë¼ìš´ë“œ)
- ë„êµ¬ í˜¸ì¶œ ë° ì‹¤í–‰
- ì±„íŒ… íˆìŠ¤í† ë¦¬ ê´€ë¦¬
- ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬

#### 3. `src/utils/settings-manager.ts` - ì„¤ì • ê´€ë¦¬
**ì—­í• **: ì‚¬ìš©ì ë° í”„ë¡œì íŠ¸ ì„¤ì • ê´€ë¦¬

**ì„¤ì • ìš°ì„ ìˆœìœ„**:
1. í™˜ê²½ ë³€ìˆ˜ (`GROK_API_KEY`, `GROK_BASE_URL`, `GROK_MODEL`)
2. ëª…ë ¹ì¤„ í”Œë˜ê·¸ (`--api-key`, `--base-url`, `--model`)
3. í”„ë¡œì íŠ¸ ì„¤ì • (`.grok/settings.json`)
4. ì‚¬ìš©ì ì„¤ì • (`~/.grok/user-settings.json`)
5. ì‹œìŠ¤í…œ ê¸°ë³¸ê°’

#### 4. `src/index.ts` - CLI ì—”íŠ¸ë¦¬
**ì—­í• **: CLI ì¸í„°í˜ì´ìŠ¤ ë° ëª…ë ¹ ì²˜ë¦¬

**ì£¼ìš” ëª…ë ¹**:
- `grok` - ëŒ€í™”í˜• ëª¨ë“œ
- `grok --prompt "..."` - í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ
- `grok git commit-and-push` - Git ìë™í™”
- `grok mcp` - MCP ì„œë²„ ê´€ë¦¬

## API í˜¸ì¶œ ë©”ì»¤ë‹ˆì¦˜

### OpenAI SDK ê¸°ë°˜ êµ¬ì¡°

Grok CLIëŠ” OpenAI SDKë¥¼ ì‚¬ìš©í•˜ì—¬ APIë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤. ì´ëŠ” ë‹¤ìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤:

1. **í‘œì¤€ OpenAI ë©”ì‹œì§€ í˜•ì‹ ì‚¬ìš©**
   ```typescript
   interface Message {
     role: "system" | "user" | "assistant" | "tool";
     content: string;
     tool_calls?: ToolCall[];
   }
   ```

2. **ë„êµ¬ í˜¸ì¶œ(Function Calling) ì§€ì›**
   ```typescript
   interface GrokTool {
     type: "function";
     function: {
       name: string;
       description: string;
       parameters: {
         type: "object";
         properties: Record<string, any>;
         required: string[];
       };
     };
   }
   ```

3. **ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì§€ì›**
   - `chatStream()` ë©”ì„œë“œë¡œ ì‹¤ì‹œê°„ ì‘ë‹µ ì²˜ë¦¬
   - ì²­í¬ ë‹¨ìœ„ë¡œ í† í° ì¹´ìš´íŒ…

### ë°ì´í„° íë¦„

```
ì‚¬ìš©ì ì…ë ¥
  â†“
ChatInterface (UI)
  â†“
GrokAgent.processUserMessage()
  â†“
GrokClient.chat() / chatStream()
  â†“
OpenAI SDK
  â†“
API ì—”ë“œí¬ì¸íŠ¸ (baseURL)
  â†“
ì‘ë‹µ ìŠ¤íŠ¸ë¦¼
  â†“
ë„êµ¬ ì‹¤í–‰ (í•„ìš”ì‹œ)
  â†“
ìµœì¢… ì‘ë‹µ ë°˜í™˜
```

## ë¡œì»¬ ëª¨ë¸ í†µí•© ë°©ë²•

### ë°©ë²• 1: OpenAI í˜¸í™˜ ì„œë²„ ì‚¬ìš©

ê°€ì¥ ê°„ë‹¨í•œ ë°©ë²•ì€ ë¡œì»¬ ëª¨ë¸ì„ OpenAI í˜¸í™˜ APIë¡œ ì œê³µí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

#### ì¶”ì²œ ë„êµ¬:
1. **vLLM** - ê³ ì„±ëŠ¥ LLM ì„œë¹™
2. **LM Studio** - GUI ê¸°ë°˜ ë¡œì»¬ ëª¨ë¸ ì„œë²„
3. **Ollama** - ê°„í¸í•œ ë¡œì»¬ ëª¨ë¸ ì‹¤í–‰
4. **text-generation-webui** (oobabooga) - OpenAI í˜¸í™˜ API ì œê³µ

#### ì˜ˆ: vLLMìœ¼ë¡œ gpt-oss-20b ì„œë¹™

```bash
# vLLM ì„¤ì¹˜
pip install vllm

# OpenAI í˜¸í™˜ ì„œë²„ ì‹¤í–‰
python -m vllm.entrypoints.openai.api_server \
  --model gpt-oss/gpt-oss-20b \
  --host 0.0.0.0 \
  --port 8000
```

#### Grok CLI ì„¤ì •

**ë°©ë²• 1: í™˜ê²½ ë³€ìˆ˜**
```bash
export GROK_API_KEY="not-needed"  # ë˜ëŠ” ë¹ˆ ë¬¸ìì—´
export GROK_BASE_URL="http://localhost:8000/v1"
export GROK_MODEL="gpt-oss/gpt-oss-20b"

grok
```

**ë°©ë²• 2: ì‚¬ìš©ì ì„¤ì • íŒŒì¼**
`~/.grok/user-settings.json`:
```json
{
  "apiKey": "not-needed",
  "baseURL": "http://localhost:8000/v1",
  "defaultModel": "gpt-oss/gpt-oss-20b",
  "models": [
    "gpt-oss/gpt-oss-20b",
    "Qwen/Qwen2.5-Coder-32B-Instruct",
    "deepseek-ai/DeepSeek-Coder-V2-Instruct"
  ]
}
```

**ë°©ë²• 3: ëª…ë ¹ì¤„ í”Œë˜ê·¸**
```bash
grok --api-key "not-needed" \
     --base-url "http://localhost:8000/v1" \
     --model "gpt-oss/gpt-oss-20b"
```

### ë°©ë²• 2: Ollama ì‚¬ìš©

OllamaëŠ” ë¡œì»¬ ëª¨ë¸ ì‹¤í–‰ì„ ë§¤ìš° ê°„ë‹¨í•˜ê²Œ ë§Œë“¤ì–´ì¤ë‹ˆë‹¤.

```bash
# Ollama ì„¤ì¹˜
curl -fsSL https://ollama.com/install.sh | sh

# ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ì‹¤í–‰
ollama pull qwen2.5-coder:32b
ollama serve
```

Grok CLI ì„¤ì •:
```bash
export GROK_API_KEY="ollama"
export GROK_BASE_URL="http://localhost:11434/v1"
export GROK_MODEL="qwen2.5-coder:32b"

grok
```

### ë°©ë²• 3: LM Studio ì‚¬ìš©

1. LM Studio ë‹¤ìš´ë¡œë“œ ë° ì„¤ì¹˜
2. ì›í•˜ëŠ” ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (ì˜ˆ: qwen3-coder)
3. "Local Server" íƒ­ì—ì„œ ì„œë²„ ì‹œì‘ (í¬íŠ¸: 1234)

Grok CLI ì„¤ì •:
```bash
export GROK_BASE_URL="http://localhost:1234/v1"
export GROK_MODEL="qwen3-coder"
grok
```

## ì„¤ì • ê´€ë¦¬ ì‹œìŠ¤í…œ

### ì„¤ì • íŒŒì¼ ìœ„ì¹˜

#### 1. ì‚¬ìš©ì ì„¤ì • (`~/.grok/user-settings.json`)
ì „ì—­ ì„¤ì •ìœ¼ë¡œ ëª¨ë“  í”„ë¡œì íŠ¸ì— ì ìš©ë©ë‹ˆë‹¤.

```json
{
  "apiKey": "your-api-key",
  "baseURL": "http://localhost:8000/v1",
  "defaultModel": "gpt-oss/gpt-oss-20b",
  "models": [
    "gpt-oss/gpt-oss-20b",
    "Qwen/Qwen2.5-Coder-32B-Instruct"
  ]
}
```

#### 2. í”„ë¡œì íŠ¸ ì„¤ì • (`.grok/settings.json`)
í”„ë¡œì íŠ¸ë³„ ì„¤ì •ìœ¼ë¡œ ì‚¬ìš©ì ì„¤ì •ì„ ì˜¤ë²„ë¼ì´ë“œí•©ë‹ˆë‹¤.

```json
{
  "model": "Qwen/Qwen2.5-Coder-32B-Instruct",
  "mcpServers": {
    "linear": {
      "name": "linear",
      "transport": "stdio",
      "command": "npx",
      "args": ["@linear/mcp-server"]
    }
  }
}
```

### ì„¤ì • ìš°ì„ ìˆœìœ„

```
ëª…ë ¹ì¤„ í”Œë˜ê·¸ (--model)
  â†“
í™˜ê²½ ë³€ìˆ˜ (GROK_MODEL)
  â†“
í”„ë¡œì íŠ¸ ì„¤ì • (.grok/settings.json)
  â†“
ì‚¬ìš©ì ê¸°ë³¸ ì„¤ì • (~/.grok/user-settings.json)
  â†“
ì‹œìŠ¤í…œ ê¸°ë³¸ê°’ (grok-code-fast-1)
```

### SettingsManager API

```typescript
const manager = getSettingsManager();

// API í‚¤ ê°€ì ¸ì˜¤ê¸°
const apiKey = manager.getApiKey();

// Base URL ê°€ì ¸ì˜¤ê¸°
const baseURL = manager.getBaseURL();

// í˜„ì¬ ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°
const currentModel = manager.getCurrentModel();

// ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡
const models = manager.getAvailableModels();

// ì„¤ì • ì—…ë°ì´íŠ¸
manager.updateUserSetting('defaultModel', 'new-model');
manager.updateProjectSetting('model', 'project-model');
```

## ì»¤ìŠ¤í„°ë§ˆì´ì§• ë¡œë“œë§µ

### Phase 1: ê¸°ë³¸ ë¡œì»¬ ëª¨ë¸ í†µí•© âœ… (í˜„ì¬)

**ëª©í‘œ**: Grok API ëŒ€ì‹  ë¡œì»¬ ëª¨ë¸ ì‚¬ìš©

**ì‘ì—… í•­ëª©**:
- [x] ì½”ë“œë² ì´ìŠ¤ ë¶„ì„
- [x] API í˜¸ì¶œ ë©”ì»¤ë‹ˆì¦˜ ì´í•´
- [ ] vLLM/Ollama ì„œë²„ ì„¤ì •
- [ ] í™˜ê²½ ë³€ìˆ˜ ë° ì„¤ì • íŒŒì¼ êµ¬ì„±
- [ ] ê¸°ë³¸ ë™ì‘ í…ŒìŠ¤íŠ¸

**ì˜ˆìƒ ì†Œìš” ì‹œê°„**: 1-2ì‹œê°„

### Phase 2: ë‹¤ì¤‘ ëª¨ë¸ ì§€ì›

**ëª©í‘œ**: ì—¬ëŸ¬ ë¡œì»¬ ëª¨ë¸ ê°„ ì‰½ê²Œ ì „í™˜

**ì‘ì—… í•­ëª©**:
- [ ] ëª¨ë¸ í”„ë¦¬ì…‹ ìƒì„± (gpt-oss-20b, qwen3-coder, deepseek-coder ë“±)
- [ ] UIì— ëª¨ë¸ ì„ íƒ ê¸°ëŠ¥ ì¶”ê°€
- [ ] ëª¨ë¸ë³„ íŒŒë¼ë¯¸í„° íŠœë‹ (temperature, max_tokens ë“±)
- [ ] ëª¨ë¸ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí‚¹

**ì˜ˆìƒ ì†Œìš” ì‹œê°„**: 3-4ì‹œê°„

### Phase 3: ë„êµ¬ í˜¸ì¶œ ìµœì í™”

**ëª©í‘œ**: ë¡œì»¬ ëª¨ë¸ì˜ ë„êµ¬ í˜¸ì¶œ ì„±ëŠ¥ í–¥ìƒ

**ì‘ì—… í•­ëª©**:
- [ ] ë¡œì»¬ ëª¨ë¸ì˜ function calling ëŠ¥ë ¥ í‰ê°€
- [ ] í•„ìš”ì‹œ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ìœ¼ë¡œ ë„êµ¬ í˜¸ì¶œ ê°œì„ 
- [ ] ReAct íŒ¨í„´ êµ¬í˜„ (ëª¨ë¸ì´ ë„êµ¬ í˜¸ì¶œì„ ì˜ ëª»í•˜ëŠ” ê²½ìš°)
- [ ] ë„êµ¬ ì‚¬ìš© ë¡œê·¸ ë° ë””ë²„ê¹…

**ì˜ˆìƒ ì†Œìš” ì‹œê°„**: 4-6ì‹œê°„

### Phase 4: ì„±ëŠ¥ ìµœì í™”

**ëª©í‘œ**: ë¡œì»¬ ëª¨ë¸ì˜ ì‘ë‹µ ì†ë„ ë° í’ˆì§ˆ í–¥ìƒ

**ì‘ì—… í•­ëª©**:
- [ ] í† í° ì¹´ìš´íŒ… ìµœì í™” (ë¡œì»¬ ëª¨ë¸ì— ë§ê²Œ)
- [ ] ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° ê´€ë¦¬
- [ ] ë°°ì¹˜ ì²˜ë¦¬ ë° ìºì‹±
- [ ] GPU ë©”ëª¨ë¦¬ ìµœì í™”

**ì˜ˆìƒ ì†Œìš” ì‹œê°„**: 5-8ì‹œê°„

### Phase 5: ê³ ê¸‰ ê¸°ëŠ¥

**ëª©í‘œ**: ì¶”ê°€ ê¸°ëŠ¥ ë° ì‚¬ìš©ì ê²½í—˜ ê°œì„ 

**ì‘ì—… í•­ëª©**:
- [ ] ëª¨ë¸ ì•™ìƒë¸” (ì—¬ëŸ¬ ëª¨ë¸ ë™ì‹œ ì‚¬ìš©)
- [ ] RAG (Retrieval-Augmented Generation) í†µí•©
- [ ] ì»¤ìŠ¤í…€ ë„êµ¬ í”ŒëŸ¬ê·¸ì¸ ì‹œìŠ¤í…œ
- [ ] ì›¹ UI ê°œë°œ (ì„ íƒì‚¬í•­)

**ì˜ˆìƒ ì†Œìš” ì‹œê°„**: 10-15ì‹œê°„

## ê¸°ìˆ ì  ê³ ë ¤ì‚¬í•­

### 1. ë„êµ¬ í˜¸ì¶œ (Function Calling)

ë¡œì»¬ ëª¨ë¸ì€ Grok/GPT-4ì™€ ë‹¬ë¦¬ ë„êµ¬ í˜¸ì¶œ ëŠ¥ë ¥ì´ ì œí•œì ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**í•´ê²° ë°©ë²•**:
- **Qwen2.5-Coder**: ë„¤ì´í‹°ë¸Œ function calling ì§€ì›
- **ê¸°íƒ€ ëª¨ë¸**: í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ìœ¼ë¡œ JSON ì¶œë ¥ ìœ ë„

```typescript
// ë„êµ¬ í˜¸ì¶œì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ì˜ˆì‹œ
const systemPrompt = `
You are an AI assistant that can use tools.
When you need to use a tool, output JSON in this format:
{
  "tool": "view_file",
  "arguments": {
    "path": "/path/to/file"
  }
}
`;
```

### 2. ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš°

ë¡œì»¬ ëª¨ë¸ì˜ ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš°ëŠ” ë‹¤ì–‘í•©ë‹ˆë‹¤:
- GPT-OSS-20B: ~8K í† í°
- Qwen2.5-Coder-32B: ~32K í† í°
- DeepSeek-Coder-V2: ~128K í† í°

**ê´€ë¦¬ ë°©ë²•**:
```typescript
// src/grok/client.tsì—ì„œ ëª¨ë¸ë³„ max_tokens ì„¤ì •
const MODEL_CONFIGS = {
  'gpt-oss/gpt-oss-20b': { maxTokens: 2048, contextWindow: 8192 },
  'Qwen/Qwen2.5-Coder-32B-Instruct': { maxTokens: 4096, contextWindow: 32768 },
  'deepseek-ai/DeepSeek-Coder-V2-Instruct': { maxTokens: 8192, contextWindow: 131072 }
};
```

### 3. í† í° ì¹´ìš´íŒ…

í˜„ì¬ `tiktoken` ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” OpenAI ëª¨ë¸ìš©ì…ë‹ˆë‹¤. ë¡œì»¬ ëª¨ë¸ìš©ìœ¼ë¡œ êµì²´ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**ëŒ€ì•ˆ**:
```typescript
// ê°„ë‹¨í•œ í† í° ì¶”ì • (ì •í™•ë„ëŠ” ë–¨ì–´ì§€ì§€ë§Œ ë¹ ë¦„)
function estimateTokens(text: string): number {
  return Math.ceil(text.length / 4);
}

// ëª¨ë¸ë³„ í† í¬ë‚˜ì´ì € ì‚¬ìš©
import { AutoTokenizer } from '@xenova/transformers';
const tokenizer = await AutoTokenizer.from_pretrained('Qwen/Qwen2.5-Coder-32B-Instruct');
```

### 4. ìŠ¤íŠ¸ë¦¬ë°

OpenAI SDKì˜ ìŠ¤íŠ¸ë¦¬ë°ì€ ëŒ€ë¶€ë¶„ì˜ OpenAI í˜¸í™˜ ì„œë²„ì—ì„œ ì‘ë™í•©ë‹ˆë‹¤.

**í™•ì¸ ì‚¬í•­**:
- vLLM: âœ… ìŠ¤íŠ¸ë¦¬ë° ì§€ì›
- Ollama: âœ… ìŠ¤íŠ¸ë¦¬ë° ì§€ì›
- LM Studio: âœ… ìŠ¤íŠ¸ë¦¬ë° ì§€ì›

## ì½”ë“œ ìˆ˜ì • í¬ì¸íŠ¸

### ìµœì†Œí•œì˜ ìˆ˜ì •ìœ¼ë¡œ ë¡œì»¬ ëª¨ë¸ ì‚¬ìš©í•˜ê¸°

ì‹¤ì œë¡œëŠ” **ì½”ë“œ ìˆ˜ì • ì—†ì´** í™˜ê²½ ë³€ìˆ˜ë§Œìœ¼ë¡œ ë¡œì»¬ ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```bash
# 1. ë¡œì»¬ ì„œë²„ ì‹¤í–‰ (ì˜ˆ: vLLM)
python -m vllm.entrypoints.openai.api_server \
  --model Qwen/Qwen2.5-Coder-32B-Instruct \
  --port 8000

# 2. Grok CLI ì‹¤í–‰
export GROK_API_KEY="local"
export GROK_BASE_URL="http://localhost:8000/v1"
export GROK_MODEL="Qwen/Qwen2.5-Coder-32B-Instruct"
grok
```

### ì„ íƒì  ê°œì„  ì‚¬í•­

ë” ë‚˜ì€ ì‚¬ìš©ì ê²½í—˜ì„ ìœ„í•´ ë‹¤ìŒ íŒŒì¼ë“¤ì„ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

#### 1. `src/utils/settings-manager.ts`
ë¡œì»¬ ëª¨ë¸ í”„ë¦¬ì…‹ ì¶”ê°€:

```typescript
const DEFAULT_USER_SETTINGS: Partial<UserSettings> = {
  baseURL: "http://localhost:8000/v1",  // ë¡œì»¬ ì„œë²„ë¡œ ë³€ê²½
  defaultModel: "Qwen/Qwen2.5-Coder-32B-Instruct",
  models: [
    "Qwen/Qwen2.5-Coder-32B-Instruct",
    "gpt-oss/gpt-oss-20b",
    "deepseek-ai/DeepSeek-Coder-V2-Instruct",
  ],
};
```

#### 2. `src/grok/client.ts`
ëª¨ë¸ë³„ ì„¤ì • ì¶”ê°€:

```typescript
const MODEL_CONFIGS: Record<string, { maxTokens: number; temperature: number }> = {
  'Qwen/Qwen2.5-Coder-32B-Instruct': {
    maxTokens: 4096,
    temperature: 0.3  // ì½”ë“œ ìƒì„±ì— ìµœì í™”
  },
  'gpt-oss/gpt-oss-20b': {
    maxTokens: 2048,
    temperature: 0.7
  },
};

constructor(apiKey: string, model?: string, baseURL?: string) {
  // ...
  const config = MODEL_CONFIGS[model || this.currentModel];
  if (config) {
    this.defaultMaxTokens = config.maxTokens;
  }
}
```

#### 3. `src/index.ts`
ë¡œì»¬ ëª¨ë¸ ì‚¬ìš©ì‹œ API í‚¤ ê²€ì¦ ì™„í™”:

```typescript
// API í‚¤ ê²€ì¦ ìˆ˜ì •
const apiKey = options.apiKey || loadApiKey() || "local-model";

// ë¡œì»¬ ì„œë²„ ì‚¬ìš©ì‹œ ê²½ê³  ì œê±°
if (baseURL?.includes('localhost') || baseURL?.includes('127.0.0.1')) {
  console.log('ğŸ  Using local model server at', baseURL);
}
```

## ë””ë²„ê¹… ë° ë¬¸ì œ í•´ê²°

### ë¡œê¹… í™œì„±í™”

```bash
# í™˜ê²½ ë³€ìˆ˜ë¡œ ë””ë²„ê·¸ ëª¨ë“œ
export DEBUG=grok:*
export GROK_LOG_LEVEL=debug

grok
```

### ì¼ë°˜ì ì¸ ë¬¸ì œ

#### 1. ì—°ê²° ì˜¤ë¥˜
```
Error: Grok API error: connect ECONNREFUSED 127.0.0.1:8000
```

**í•´ê²°ì±…**: ë¡œì»¬ ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸
```bash
curl http://localhost:8000/v1/models
```

#### 2. ë„êµ¬ í˜¸ì¶œ ì‹¤íŒ¨
```
Error: Tool execution error: ...
```

**í•´ê²°ì±…**: ëª¨ë¸ì´ function callingì„ ì§€ì›í•˜ëŠ”ì§€ í™•ì¸. ì§€ì›í•˜ì§€ ì•Šìœ¼ë©´ ReAct íŒ¨í„´ êµ¬í˜„ í•„ìš”.

#### 3. í† í° ì œí•œ ì´ˆê³¼
```
Error: Token limit exceeded
```

**í•´ê²°ì±…**: `GROK_MAX_TOKENS` ì¡°ì • ë˜ëŠ” ëŒ€í™” íˆìŠ¤í† ë¦¬ ì •ë¦¬
```bash
export GROK_MAX_TOKENS=2048
```

## ì°¸ê³  ìë£Œ

### ë¡œì»¬ ëª¨ë¸ ì„œë¹™
- [vLLM ë¬¸ì„œ](https://docs.vllm.ai/)
- [Ollama ë¬¸ì„œ](https://ollama.com/docs)
- [LM Studio](https://lmstudio.ai/)

### ì¶”ì²œ ëª¨ë¸
- **Qwen2.5-Coder-32B**: ì½”ë“œ ìƒì„± ë° ë„êµ¬ í˜¸ì¶œì— ìš°ìˆ˜
- **DeepSeek-Coder-V2**: ê¸´ ì»¨í…ìŠ¤íŠ¸ ì§€ì›
- **GPT-OSS-20B**: ì˜¤í”ˆì†ŒìŠ¤ ëŒ€ì•ˆ

### OpenAI í˜¸í™˜ API
- [OpenAI API ë ˆí¼ëŸ°ìŠ¤](https://platform.openai.com/docs/api-reference)
- [vLLM OpenAI í˜¸í™˜ ì„œë²„](https://docs.vllm.ai/en/latest/serving/openai_compatible_server.html)

## ë‹¤ìŒ ë‹¨ê³„

1. **ë¡œì»¬ ì„œë²„ ì„¤ì •**: vLLM ë˜ëŠ” Ollamaë¡œ ì›í•˜ëŠ” ëª¨ë¸ ì‹¤í–‰
2. **í™˜ê²½ ë³€ìˆ˜ êµ¬ì„±**: `GROK_BASE_URL`ê³¼ `GROK_MODEL` ì„¤ì •
3. **í…ŒìŠ¤íŠ¸**: ê¸°ë³¸ ëª…ë ¹ìœ¼ë¡œ ë™ì‘ í™•ì¸
4. **ìµœì í™”**: ëª¨ë¸ë³„ íŒŒë¼ë¯¸í„° íŠœë‹
5. **ê³ ê¸‰ ê¸°ëŠ¥**: ì»¤ìŠ¤í…€ ë„êµ¬ ë° í”„ë¡¬í”„íŠ¸ ì¶”ê°€

ê¶ê¸ˆí•œ ì ì´ë‚˜ ë¬¸ì œê°€ ë°œìƒí•˜ë©´ ì´ìŠˆë¥¼ ì—´ì–´ì£¼ì„¸ìš”!
